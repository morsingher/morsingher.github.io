<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Marco Orsingher</title>
  
  <meta name="author" content="Marco Orsingher">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ü§ñ</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Marco Orsingher</name>
              </p>
              <p>
                I am a senior algorithm engineer at <a href="https://vislab.it/">VisLab</a> (an <a href="https://www.ambarella.com/">Ambarella Inc.</a> company), where I work on 3D reconstruction for self-driving cars. I got my PhD in computer vision from <a href="https://www.unipr.it">Universit√† degli Studi di Parma</a>, while collaborating with Ambarella Inc. research teams in Italy and Taiwan. I was also a visiting scholar at <a href="https://en.nycu.edu.tw/">NYCU</a>, working on knowledge distillation and neural network compression.
              </p>
              <p>
                Previously, I was a software engineer at <a href="https://yapemobility.it/">YAPE</a>, designing full-stack autonomous navigation algorithms for a two-wheeled delivery robot. I hold a MSc in robotics engineering from <a href="https://unige.it/it/">Universit√† degli Studi di Genova</a> and <a href="https://www.ec-nantes.fr/english-version">Ecole Centrale de Nantes</a> (double degree), as well as a BSc in control engineering from <a href="https://polimi.it/">Politecnico di Milano</a>.
              </p>
              <p style="text-align:center">
                <a href="mailto:m.orsingher@yahoo.com">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=pNaXtyIAAAAJ&hl=it">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/marco-orsingher-800446132/">LinkedIn</a> &nbsp/&nbsp
                <a href="https://github.com/morsingher">GitHub</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/profile_pic_small.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/profile_pic_small.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
              I am broadly interested in computer vision and machine learning, especially in self-driving scenarios. The goal of my research is to combine geometry and learning for efficient, large-scale 3D understanding with cheap sensors.
              </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/unipr.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://drive.google.com/file/d/1ZIRAhuSX0E6qRw-Fnub08TKKiwTyUXRk/view?usp=drive_link">
                <papertitle>Geometry and Learning for Efficient 3D Perception</papertitle>
              </a>
              <br>
              <strong>Marco Orsingher</strong>
              <br>
              <em>PhD Thesis</em>, 2024
              <br>
              <a href="https://drive.google.com/file/d/1ZIRAhuSX0E6qRw-Fnub08TKKiwTyUXRk/view?usp=drive_link">Thesis</a> /
              <a href="data/thesis.bib">BibTeX</a>
              <p></p>
              <p>
A collection of previous works, with additional details, visualizations and experiments, as well as the proper context on how they fit into my research goals.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/visapp.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2312.17561.pdf">
                <papertitle>Informative Rays Selection for Few-Shot Neural Radiance Fields</papertitle>
              </a>
              <br>
              <strong>Marco Orsingher</strong>,
              <a href="https://scholar.google.com/citations?user=SQOz2A0AAAAJ&hl=en">Anthony Dell'Eva</a>,
              <a href="https://scholar.google.com/citations?hl=it&user=og3JnIYAAAAJ">Paolo Zani</a>, 
              <a href="http://www.ce.unipr.it/people/medici/about.php">Paolo Medici</a>,
              <a href="http://www.ce.unipr.it/people/bertozzi/">Massimo Bertozzi</a>
              <br>
              <em>VISAPP</em>, 2024
              <br>
              <a href="https://arxiv.org/pdf/2312.17561.pdf">Paper</a> /
              <a href="https://www.youtube.com/watch?v=XOMwNJ9y760">Video</a> /
              <a href="https://github.com/morsingher/keynerf">Code</a> /
              <a href="data/visapp.bib">BibTeX</a>
              <p></p>
              <p>
We analyze the sampling efficiency of NeRF and present two strategies to optimize it, given a limited training budget.
              </p>
            </td>
          </tr>  

        <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/eccvw.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2210.13041.pdf">
                <papertitle>Learning Neural Radiance Fields from Multi-View Geometry</papertitle>
              </a>
              <br>
              <strong>Marco Orsingher</strong>,
              <a href="https://scholar.google.com/citations?hl=it&user=og3JnIYAAAAJ">Paolo Zani</a>, 
              <a href="http://www.ce.unipr.it/people/medici/about.php">Paolo Medici</a>,
              <a href="http://www.ce.unipr.it/people/bertozzi/">Massimo Bertozzi</a>
              <br>
              <em>ECCV Workshop</em>, 2022
              <br>
              <a href="https://arxiv.org/pdf/2210.13041.pdf">Paper</a> /
              <a href="https://www.youtube.com/watch?v=rG5O3QMoq0g">Video</a> /
              <a href="data/eccvw.bib">BibTeX</a>
              <p></p>
              <p>
We use classical 3D reconstruction as pseudo-supervision for training NeRF and obtain much cleaner surfaces.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/3dv.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://apusmog.github.io/">
                <papertitle>Arbitrary Point Cloud Upsampling with Spherical Mixture of Gaussians</papertitle>
              </a>
              <br>
              <a href="https://scholar.google.com/citations?user=SQOz2A0AAAAJ&hl=en">Anthony Dell'Eva</a> (*),
              <strong>Marco Orsingher</strong> (*),
              <a href="http://www.ce.unipr.it/people/bertozzi/">Massimo Bertozzi</a>
              (*Equal Contribution) 
              <br>
              <em>3DV</em>, 2022 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
              <br>
              <a href="https://apusmog.github.io/">Project Page</a> /
              <a href="https://arxiv.org/pdf/2208.05274.pdf">Paper</a> /
              <a href="https://www.youtube.com/watch?v=u0JBt5Gxs8w">Video</a> /
              <a href="https://github.com/apusmog/apusmog/">Code</a> /
              <a href="data/3dv.bib">BibTeX</a>
              <p></p>
              <p>
We show that Transformers can learn to generate point clouds with arbitrary resolution from sparse raw data.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/iv.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2207.08439.pdf">
                <papertitle>Revisiting PatchMatch Multi-View Stereo for Urban 3D Reconstruction</papertitle>
              </a>
              <br>
              <strong>Marco Orsingher</strong>,
              <a href="https://scholar.google.com/citations?hl=it&user=og3JnIYAAAAJ">Paolo Zani</a>, 
              <a href="http://www.ce.unipr.it/people/medici/about.php">Paolo Medici</a>,
              <a href="http://www.ce.unipr.it/people/bertozzi/">Massimo Bertozzi</a>
              <br>
              <em>IEEE IV</em>, 2022
              <br>
              <a href="https://arxiv.org/pdf/2207.08439.pdf">Paper</a> /
              <a href="data/iv.bib">BibTeX</a>
              <p></p>
              <p>
We propose a framework for monocular 3D reconstruction that combines visual SLAM, multi-scale PatchMatch MVS with planar priors and confidence-based graph optimization.
              </p>
            </td>
          </tr>   

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/iciap.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2207.08434.pdf">
                <papertitle>Efficient View Clustering and Selection for City-Scale 3D Reconstruction</papertitle>
              </a>
              <br>
              <strong>Marco Orsingher</strong>,
              <a href="https://scholar.google.com/citations?hl=it&user=og3JnIYAAAAJ">Paolo Zani</a>, 
              <a href="http://www.ce.unipr.it/people/medici/about.php">Paolo Medici</a>,
              <a href="http://www.ce.unipr.it/people/bertozzi/">Massimo Bertozzi</a>
              <br>
              <em>ICIAP</em>, 2021 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
              <br>
              <a href="https://arxiv.org/pdf/2207.08434.pdf">Paper</a> /
              <a href="https://www.youtube.com/watch?v=SWkYM_qAcTQ">Video</a> /
              <a href="data/iciap.bib">BibTeX</a>
              <p></p>
              <p>
We design a view selection algorithm that scales linearly with the number of clusters and allows to reconstruct efficiently entire cities.
              </p>
            </td>
          </tr>     
					
        </tbody></table>

      </td>
    </tr>
  </table>
</body>

</html>
